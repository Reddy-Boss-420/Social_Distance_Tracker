{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jetson.inference\n",
    "import jetson.utils\n",
    "import ipywidgets \n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg as col\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_close(p1, p2):\n",
    "    dst = math.sqrt(p1 ** 2 + p2 ** 2)\n",
    "    return dst \n",
    "def convertBack(x, y, w, h): \n",
    "    #================================================================\n",
    "    # 2.Purpose : Converts center coordinates to rectangle coordinates\n",
    "    #================================================================  \n",
    "    \"\"\"\n",
    "    :param:\n",
    "    x, y = midpoint of bbox\n",
    "    w, h = width, height of the bbox\n",
    "    \n",
    "    :return:\n",
    "    xmin, ymin, xmax, ymax\n",
    "    \"\"\"\n",
    "    xmin = int(round(x - (w / 2)))\n",
    "    xmax = int(round(x + (w / 2)))\n",
    "    ymin = int(round(y - (h / 2)))\n",
    "    ymax = int(round(y + (h / 2)))\n",
    "    return xmin, ymin, xmax, ymax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvDrawBoxes(detections, img,distthresh):\n",
    "    \"\"\"\n",
    "    :param:\n",
    "    detections = total detections in one frame\n",
    "    img = image from detect_image method of darknet\n",
    "    :return:\n",
    "    img with bbox\n",
    "    \"\"\"\n",
    "    #================================================================\n",
    "    # 3.1 Purpose : Filter out Persons class from detections and get \n",
    "    #           bounding box centroid for each person detection.\n",
    "    #================================================================\n",
    "    if len(detections) > 0:  \t\t\t\t\t\t# At least 1 detection in the image and check detection presence in a frame  \n",
    "        centroid_dict = dict() \t\t\t\t\t\t# Function creates a dictionary and calls it centroid_dict\n",
    "        objectId = 0\t\t\t\t\t\t\t\t# We inialize a variable called ObjectId and set it to 0\n",
    "        for detection in detections:\t\t\t\t# In this if statement, we filter all the detections for persons only\n",
    "            # Check for the only person name tag \n",
    "            name_tag = detection.ClassID\n",
    "            if name_tag != 1:                \n",
    "                x, y, w, h = detection.Center[0],\\\n",
    "                            detection.Center[1],\\\n",
    "                            detection.Width,\\\n",
    "                            detection.Height      \t# Store the center points of the detections\n",
    "                xmin, ymin, xmax, ymax = convertBack(float(x), float(y), float(w), float(h))   # Convert from center coordinates to rectangular coordinates, We use floats to ensure the precision of the BBox            \n",
    "                # Append center point of bbox for persons detected.\n",
    "                centroid_dict[objectId] = (int(x), int(y), xmin, ymin, xmax, ymax) # Create dictionary of tuple with 'objectId' as the index center points and bbox\n",
    "                objectId += 1 #Increment the index for each detection      \n",
    "    #=================================================================#\n",
    "    \n",
    "    #=================================================================\n",
    "    # 3.2 Purpose : Determine which person bbox are close to each other\n",
    "    #=================================================================            \t\n",
    "        red_zone_list = [] # List containing which Object id is in under threshold distance condition. \n",
    "        red_line_list = []\n",
    "        for (id1, p1), (id2, p2) in combinations(centroid_dict.items(), 2): # Get all the combinations of close detections, #List of multiple items - id1 1, points 2, 1,3\n",
    "            dx, dy = p1[0] - p2[0], p1[1] - p2[1]  \t# Check the difference between centroid x: 0, y :1\n",
    "            distance = is_close(dx, dy) \t\t\t# Calculates the Euclidean distance\n",
    "            if distance <= distthresh:\t\t\t\t\t\t# Set our social distance threshold - If they meet this condition then..\n",
    "                if id1 not in red_zone_list:\n",
    "                    red_zone_list.append(id1)       #  Add Id to a list\n",
    "                    red_line_list.append(p1[0:2])   #  Add points to the list\n",
    "                if id2 not in red_zone_list:\n",
    "                    red_zone_list.append(id2)\t\t# Same for the second id \n",
    "                    red_line_list.append(p2[0:2])\n",
    "        \n",
    "        for idx, box in centroid_dict.items():  # dict (1(key):red(value), 2 blue)  idx - key  box - value\n",
    "            if idx in red_zone_list:   # if id is in red zone list\n",
    "                cv2.rectangle(img, (box[2], box[3]), (box[4], box[5]), (255, 0, 0), 2) # Create Red bounding boxes  #starting point, ending point size of 2\n",
    "            else:\n",
    "                cv2.rectangle(img, (box[2], box[3]), (box[4], box[5]), (0, 255, 0), 2) # Create Green bounding boxes\n",
    "\t\t#=================================================================#\n",
    "\n",
    "\t\t#=================================================================\n",
    "    \t# 3.3 Purpose : Display Risk Analytics and Show Risk Indicators\n",
    "    \t#=================================================================        \n",
    "        text = \"People at Risk: %s\" % str(len(red_zone_list)) \t\t\t# Count People at Risk\n",
    "        \n",
    "        location = (10,25)\t\t\t\t\t\t\t\t\t\t\t\t# Set the location of the displayed text\n",
    "        cv2.putText(img, text, location, cv2.FONT_HERSHEY_SIMPLEX, 1, (246,86,86), 2, cv2.LINE_AA)  # Display Text\n",
    "\n",
    "        for check in range(0, len(red_line_list)-1):\t\t\t\t\t# Draw line between nearby bboxes iterate through redlist items\n",
    "            start_point = red_line_list[check] \n",
    "            end_point = red_line_list[check+1]\n",
    "            check_line_x = abs(end_point[0] - start_point[0])   \t\t# Calculate the line coordinates for x  \n",
    "            check_line_y = abs(end_point[1] - start_point[1])\t\t\t# Calculate the line coordinates for y\n",
    "            #if (check_line_x < distthresh) and (check_line_y < 25):\t\t\t\t# If both are We check that the lines are below our threshold distance.\n",
    "            cv2.line(img, start_point, end_point, (255, 0, 0), 2)   # Only above the threshold lines are displayed. \n",
    "        #=================================================================#\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected cameras:  [<CameraBoardSocket.RGB: 0>, <CameraBoardSocket.LEFT: 1>, <CameraBoardSocket.RIGHT: 2>]\n",
      "Usb speed:  SUPER\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d645dbb7504f519e8acd96e7f87877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import depthai as dai\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Define source and output\n",
    "camRgb = pipeline.createColorCamera()\n",
    "xoutRgb = pipeline.createXLinkOut()\n",
    "\n",
    "xoutRgb.setStreamName(\"rgb\")\n",
    "\n",
    "# Properties\n",
    "camRgb.setPreviewSize(1280, 720)\n",
    "camRgb.setInterleaved(False)\n",
    "camRgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.RGB)\n",
    "\n",
    "# Linking\n",
    "camRgb.preview.link(xoutRgb.input)\n",
    "\n",
    "# Connect to device and start pipeline\n",
    "#with dai.Device(pipeline) as device:\n",
    "\n",
    "device = dai.Device(pipeline)\n",
    "\n",
    "print('Connected cameras: ', device.getConnectedCameras())\n",
    "# Print out usb speed\n",
    "print('Usb speed: ', device.getUsbSpeed().name)\n",
    "\n",
    "# Output queue will be used to get the rgb frames from the output defined above\n",
    "qRgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "\n",
    "inRgb = qRgb.get()  # blocking call, will wait until a new data has arrived\n",
    "\n",
    " # Retrieve 'bgr' (opencv format) frame\n",
    "#cv2.imshow(\"rgb\", inRgb.getCvFrame())\n",
    "pic = inRgb.getCvFrame()\n",
    "img = jetson.utils.cudaFromNumpy(pic)\n",
    "image_widget = ipywidgets.Image(format = 'jpeg')\n",
    "        \n",
    "\n",
    "array = jetson.utils.cudaToNumpy(img)\n",
    "    \n",
    "image_widget.value = col(array)\n",
    "display(image_widget)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = jetson.inference.detectNet(\"ped-100\",threshold=0.5)\n",
    "\n",
    "camera = jetson.utils.videoSource(\"/dev/video0\")      # '/dev/video0' for V4L2\n",
    "dis = jetson.utils.videoOutput(\"display://0\") # 'my_video.mp4' for file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96a5734cb7747e4803d95f810d3586c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_widget = ipywidgets.Image(format = 'jpeg')\n",
    "img = camera.Capture()\n",
    "\n",
    "array = jetson.utils.cudaToNumpy(img)\n",
    "\n",
    "image_widget.value = col(array)\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-741dff7a7818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverlay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjetson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaToNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while dis.IsStreaming():\n",
    "    # blocking call, will wait until a new data has arrived\n",
    "\n",
    "    # Retrieve 'bgr' (opencv format) frame\n",
    "    #cv2.imshow(\"rgb\", inRgb.getCvFrame())\n",
    "    img = camera.Capture()\n",
    "    \n",
    "    detections = net.Detect(img,overlay = 'none')\n",
    "\n",
    "    array = jetson.utils.cudaToNumpy(img)\n",
    "    cvDrawBoxes(detections, array,1000)\n",
    "    image_widget.value = col(array)\n",
    "    #display.SetStatus(\"Object Detection | Network {:.0f} FPS\".format(net.GetNetworkFPS()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4627c8121aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjetson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaFromNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjetson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaToNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage_widget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetcam-0.0.0-py3.6.egg/jetcam/utils.py\u001b[0m in \u001b[0;36mbgr8_to_jpeg\u001b[0;34m(value, quality)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbgr8_to_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while dis.IsStreaming():\n",
    "    inRgb = qRgb.get()  # blocking call, will wait until a new data has arrived\n",
    "\n",
    "    # Retrieve 'bgr' (opencv format) frame\n",
    "    #cv2.imshow(\"rgb\", inRgb.getCvFrame())\n",
    "    pic = inRgb.getCvFrame()\n",
    "    img = jetson.utils.cudaFromNumpy(pic)\n",
    "    array = jetson.utils.cudaToNumpy(img)\n",
    "    image_widget.value = col(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
